{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from misc_fun import FLAGS\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from time import time\n",
    "import os.path\n",
    "from tensorflow.python.client import timeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    REMINDER: Each time you change the mode,\n",
    "    you need to restart the Kernel by using the refresh botton\n",
    "    (may) next to the stop botton.\n",
    "\n",
    "    Choose a Model to Run\n",
    "    You Can Either Choose from:\n",
    "    1: A CNN with multiple convolution layers and two dense layers. (Work as a Control Group)\n",
    "    2: A CNN contains dropout layers\n",
    "    3: A CNN with smaller kernel and smaller layers\n",
    "    4: A CNN with bias in some of the layers\n",
    "    5: A 2-layer fully connected neural network without any convolution layers\n",
    "\"\"\"\n",
    "\n",
    "MODE = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and pre-processing data\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images /= 255\n",
    "test_images /= 255\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model with multiple layers ï¼ˆAs Control Group)\n",
    "if 1 == MODE:\n",
    "    model_CNN_multiple_layer = Sequential()\n",
    "    # convolution layer 1: 5*5 kernel is divided into 2* (3*3) kennels\n",
    "    model_CNN_multiple_layer.add(Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    model_CNN_multiple_layer.add(Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu'))\n",
    "    # pooling layer 1: max pooling method\n",
    "    model_CNN_multiple_layer.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # convolution layer 2: 5*5 kernel is divided into 2* (3*3) kennels\n",
    "    model_CNN_multiple_layer.add(Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "    ))\n",
    "    model_CNN_multiple_layer.add(Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "    ))\n",
    "    # pooling layer 1: max pooling method\n",
    "    model_CNN_multiple_layer.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_CNN_multiple_layer.add(Flatten())\n",
    "    model_CNN_multiple_layer.add(Dense(1024, activation='relu'))\n",
    "    model_CNN_multiple_layer.add(Dense(10, activation='softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2 == MODE:\n",
    "    # construct a CNN model with dropout layers\n",
    "    \n",
    "    model_CNN_with_dropout = Sequential()\n",
    "    # convolution layer 1: 5*5 kernel is divided into 2* (3*3) kennels\n",
    "    model_CNN_with_dropout.add(Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    model_CNN_with_dropout.add(Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu'))\n",
    "    # pooling layer 1: max pooling method\n",
    "    model_CNN_with_dropout.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add a drop out layer\n",
    "    model_CNN_with_dropout.add(Dropout(0.2))\n",
    "    # convolution layer 2: 5*5 kernel is divided into 2* (3*3) kennels\n",
    "    model_CNN_with_dropout.add(Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "    ))\n",
    "    model_CNN_with_dropout.add(Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "    ))\n",
    "    # pooling layer 1: max pooling method\n",
    "    model_CNN_with_dropout.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add a drop out layer\n",
    "    model_CNN_with_dropout.add(Dropout(0.2))\n",
    "    # \n",
    "    model_CNN_with_dropout.add(Flatten())\n",
    "    model_CNN_with_dropout.add(Dense(1024, activation='relu'))\n",
    "    model_CNN_with_dropout.add(Dropout(0.2))\n",
    "    model_CNN_with_dropout.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 3 == MODE:\n",
    "    # construct a CNN model with smaller kernel and fewer layers\n",
    "    \n",
    "    model_CNN_smaller_kernel = Sequential()\n",
    "    # convolution layer 1: 3*3 kernel \n",
    "    model_CNN_smaller_kernel.add(Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    # pooling layer 1: max pooling method\n",
    "    model_CNN_smaller_kernel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # convolution layer 2: 3*3 kernel\n",
    "    model_CNN_smaller_kernel.add(Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "    ))\n",
    "    model_CNN_smaller_kernel.add(Flatten())\n",
    "    model_CNN_smaller_kernel.add(Dense(1024, activation='relu'))\n",
    "    model_CNN_smaller_kernel.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 4 == MODE:\n",
    "    #contruct a model with bias inside each of the layer\n",
    "    \n",
    "    model_CNN_with_bias = Sequential()\n",
    "    # convolution layer 1: 5*5 kernel is divided into 2* (3*3) kennels\n",
    "    model_CNN_with_bias.add(Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "        input_shape=input_shape,\n",
    "        use_bias=True\n",
    "    ))\n",
    "    model_CNN_with_bias.add(Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "        use_bias=True\n",
    "    ))\n",
    "    # pooling layer 1: max pooling method\n",
    "    model_CNN_with_bias.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # convolution layer 2: 5*5 kernel is divided into 2* (3*3) kennels\n",
    "    model_CNN_with_bias.add(Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "        use_bias=True\n",
    "    ))\n",
    "    model_CNN_with_bias.add(Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation='relu',\n",
    "        use_bias=True\n",
    "    ))\n",
    "    # pooling layer 1: max pooling method\n",
    "    model_CNN_with_bias.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_CNN_with_bias.add(Flatten())\n",
    "    model_CNN_with_bias.add(Dense(1024, activation='relu',use_bias=True))\n",
    "    model_CNN_with_bias.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 5 == MODE:\n",
    "    # construct a model without convolution layers\n",
    "    model_fully_connected = Sequential()\n",
    "    model_fully_connected.add(Flatten())\n",
    "    model_fully_connected.add(Dense(1024, activation='relu'))\n",
    "    model_fully_connected.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage path for models\n",
    "multiple_layer_path = os.path.join(FLAGS.DEFAULT_OUT,'model_multiple_layers/')\n",
    "dropout_path = os.path.join(FLAGS.DEFAULT_OUT,'model_with_dropout/')\n",
    "smaller_kernel_path = os.path.join(FLAGS.DEFAULT_OUT,'model_smaller_kernel/')\n",
    "bias_path = os.path.join(FLAGS.DEFAULT_OUT,'model_with_bias/')\n",
    "fully_connected_path = os.path.join(FLAGS.DEFAULT_OUT,'model_fully_connected/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct tensorboard event files for models\n",
    "# define the paths for event files\n",
    "multi_layer_tensorboard = os.path.join(multiple_layer_path, 'logdir/{}'.format(time()))\n",
    "dropout_tensorboard = os.path.join(dropout_path, 'logdir/{}'.format(time()))\n",
    "smaller_kernel_tensorboard = os.path.join(smaller_kernel_path, 'logdir/{}'.format(time()))\n",
    "bias_tensorboard = os.path.join(bias_path, 'logdir/{}'.format(time()))\n",
    "fully_connected_tensorboard = os.path.join(fully_connected_path, 'logdir/{}'.format(time()))\n",
    "\n",
    "#create tensorboards \n",
    "# (write_images will write all images into the Tensorboard files,\n",
    "# which will significantly increase the size of the files,\n",
    "# and will not be used in this project unless required)\n",
    "if 1 == MODE:\n",
    "    tensorboard_multi = TensorBoard(log_dir=multi_layer_tensorboard.format(time()),\n",
    "                                    write_graph=True,\n",
    "                                    write_grads=True,\n",
    "                                    histogram_freq=1,\n",
    "                                    # write_images=True \n",
    "                                    )\n",
    "elif 2 == MODE:\n",
    "    tensorboard_dropout = TensorBoard(log_dir=dropout_tensorboard.format(time()),\n",
    "                                      write_graph=True,\n",
    "                                      write_grads=True,\n",
    "                                      histogram_freq=1)\n",
    "elif 3 == MODE:\n",
    "    tensorboard_smaller = TensorBoard(log_dir=smaller_kernel_tensorboard.format(time()),\n",
    "                                      write_graph=True,\n",
    "                                      write_grads=True,\n",
    "                                      histogram_freq=1)\n",
    "elif 4 == MODE:\n",
    "    tensorboard_bias = TensorBoard(log_dir=bias_tensorboard.format(time()),\n",
    "                                   write_graph=True,\n",
    "                                   write_grads=True,\n",
    "                                   histogram_freq=1)\n",
    "elif 5 == MODE:\n",
    "    tensorboard_fully = TensorBoard(log_dir=fully_connected_tensorboard.format(time()),\n",
    "                                    write_graph=True,\n",
    "                                    write_grads=True,\n",
    "                                    histogram_freq=1)\n",
    "else:\n",
    "    print('Wrong MODE, Check it!')\n",
    "    os._exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect information for Chrome timeline json files\n",
    "run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\AI_for_mechatronics\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "if 1 == MODE:\n",
    "    model_CNN_multiple_layer.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                     optimizer=keras.optimizers.Adadelta(),\n",
    "                                     metrics=['accuracy'],\n",
    "                                     # options=run_options,\n",
    "                                     run_metadata=run_metadata)\n",
    "elif 2 == MODE:\n",
    "    model_CNN_with_dropout.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                   optimizer=keras.optimizers.Adadelta(),\n",
    "                                   metrics=['accuracy'],\n",
    "                                   run_metadata=run_metadata)\n",
    "elif 3 == MODE:\n",
    "    model_CNN_smaller_kernel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                     optimizer=keras.optimizers.Adadelta(),\n",
    "                                     metrics=['accuracy'],\n",
    "                                     # options=run_options,\n",
    "                                     run_metadata=run_metadata)\n",
    "elif 4 == MODE:\n",
    "    model_CNN_with_bias.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                optimizer=keras.optimizers.Adadelta(),\n",
    "                                metrics=['accuracy'],\n",
    "                                run_metadata=run_metadata)\n",
    "elif 5 == MODE:\n",
    "    model_fully_connected.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                  optimizer=keras.optimizers.Adadelta(),\n",
    "                                  metrics=['accuracy'],\n",
    "                                  run_metadata=run_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add check points\n",
    "if 1 == MODE:\n",
    "    multiple_layer_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(multiple_layer_path,'checkpointfiles/cp-{epoch:04d}.ckpt'),\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=False,\n",
    "        period=2)\n",
    "elif 2 == MODE:\n",
    "    dropout_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(dropout_path,'checkpointfiles/cp-{epoch:04d}.ckpt'),\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=False,\n",
    "        period=2)\n",
    "elif 3 == MODE:\n",
    "    smaller_kernel_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(smaller_kernel_path,'checkpointfiles/cp-{epoch:04d}.ckpt'),\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=False,\n",
    "        period=2)\n",
    "elif 4 == MODE:\n",
    "    bias_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(bias_path,'checkpointfiles/cp-{epoch:04d}.ckpt'),\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=False,\n",
    "        period=2)\n",
    "elif 5 == MODE:\n",
    "    fully_connected_checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(fully_connected_path,'checkpointfiles/cp-{epoch:04d}.ckpt'),\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=False,\n",
    "        period=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\AI_for_mechatronics\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00002: saving model to E:/Artificial_Intelligence_for_Mechatronics/Assignment1/results/model_fully_connected/checkpointfiles/cp-0002.ckpt\nWARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adadelta object at 0x000001C95E996C18>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\AI_for_mechatronics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00004: saving model to E:/Artificial_Intelligence_for_Mechatronics/Assignment1/results/model_fully_connected/checkpointfiles/cp-0004.ckpt\nWARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adadelta object at 0x000001C95E996C18>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00006: saving model to E:/Artificial_Intelligence_for_Mechatronics/Assignment1/results/model_fully_connected/checkpointfiles/cp-0006.ckpt\nWARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adadelta object at 0x000001C95E996C18>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00008: saving model to E:/Artificial_Intelligence_for_Mechatronics/Assignment1/results/model_fully_connected/checkpointfiles/cp-0008.ckpt\nWARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adadelta object at 0x000001C95E996C18>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00010: saving model to E:/Artificial_Intelligence_for_Mechatronics/Assignment1/results/model_fully_connected/checkpointfiles/cp-0010.ckpt\nWARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adadelta object at 0x000001C95E996C18>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00012: saving model to E:/Artificial_Intelligence_for_Mechatronics/Assignment1/results/model_fully_connected/checkpointfiles/cp-0012.ckpt\nWARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adadelta object at 0x000001C95E996C18>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT FINISHED\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "if 1 == MODE:\n",
    "    model_CNN_multiple_layer.fit(train_images, train_labels,\n",
    "                                 batch_size=128,\n",
    "                                 epochs=12,\n",
    "                                 verbose=0,\n",
    "                                 validation_data=(test_images, test_labels),\n",
    "                                 callbacks=[tensorboard_multi, multiple_layer_checkpoint],\n",
    "                                 )\n",
    "elif 2 == MODE:\n",
    "    model_CNN_with_dropout.fit(train_images, train_labels,\n",
    "                               batch_size=128,\n",
    "                               epochs=12,\n",
    "                               verbose=0,\n",
    "                               validation_data=(test_images, test_labels),\n",
    "                               callbacks=[tensorboard_dropout, dropout_checkpoint],\n",
    "                               )\n",
    "elif 3 == MODE:\n",
    "    model_CNN_smaller_kernel.fit(train_images, train_labels,\n",
    "                                 batch_size=128,\n",
    "                                 epochs=12,\n",
    "                                 verbose=0,\n",
    "                                 validation_data=(test_images, test_labels),\n",
    "                                 callbacks=[tensorboard_smaller, smaller_kernel_checkpoint],\n",
    "                                 )\n",
    "elif 4 == MODE:\n",
    "    model_CNN_with_bias.fit(train_images, train_labels,\n",
    "                            batch_size=128,\n",
    "                            epochs=12,\n",
    "                            verbose=0,\n",
    "                            validation_data=(test_images, test_labels),\n",
    "                            callbacks=[tensorboard_bias, bias_checkpoint],\n",
    "                            )\n",
    "elif 5 == MODE:\n",
    "    model_fully_connected.fit(train_images, train_labels,\n",
    "                              batch_size=128,\n",
    "                              epochs=12,\n",
    "                              verbose=0,\n",
    "                              validation_data=(test_images, test_labels),\n",
    "                              callbacks=[tensorboard_fully, fully_connected_checkpoint]\n",
    "                              )\n",
    "print('FIT FINISHED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss for Fully Connected Neural Network is:        0.31421863079071044\nTest Accuracy for Fully Connected Neural Network is:  0.8906\n"
     ]
    }
   ],
   "source": [
    "if 1 == MODE:\n",
    "    score = model_CNN_multiple_layer.evaluate(test_images, test_labels, verbose=0)\n",
    "elif 2 == MODE:\n",
    "    score = model_CNN_with_dropout.evaluate(test_images, test_labels, verbose=0)\n",
    "elif 3 == MODE:\n",
    "    score = model_CNN_smaller_kernel.evaluate(test_images, test_labels, verbose=0)\n",
    "elif 4 == MODE:\n",
    "    score = model_CNN_with_bias.evaluate(test_images, test_labels, verbose=0)\n",
    "elif 5 == MODE:\n",
    "    score = model_fully_connected.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "method_name = ['Multiple Layer CNN Model',\n",
    "               'CNN Model with Dropout',\n",
    "               'CNN Model with Smaller Kernel and Less Layers',\n",
    "               'CNN Model with Bias',\n",
    "               'Fully Connected Neural Network']\n",
    "print('Test Loss for {} is:       '.format(method_name[MODE-1]), score[0])\n",
    "print('Test Accuracy for {} is: '.format(method_name[MODE-1]), score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the .json file\n",
    "# There is an unsolved issue that the program requires a cupti64_90.dll\n",
    "# when running on a NVIDIA GPU. However,this dll has been removed from the CUDA library\n",
    "# after CUDA 8.0 version.\n",
    "trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n",
    "if 1 == MODE:\n",
    "    json_path = os.path.join(multiple_layer_path, 'model.json')\n",
    "elif 2 == MODE:\n",
    "    json_path = os.path.join(dropout_path, 'model.json')\n",
    "elif 3 == MODE:\n",
    "    json_path = os.path.join(smaller_kernel_path, 'model.json')\n",
    "elif 4 == MODE:\n",
    "    json_path = os.path.join(bias_path, 'model.json')\n",
    "else:\n",
    "    json_path = os.path.join(fully_connected_path, 'model.json')\n",
    "with open(json_path, 'w')as json_file:\n",
    "    json_file.write(trace.generate_chrome_trace_format())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
